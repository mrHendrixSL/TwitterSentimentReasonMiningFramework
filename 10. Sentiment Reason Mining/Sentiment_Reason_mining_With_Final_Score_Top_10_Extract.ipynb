{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rasikac\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define the directory paths\n",
    "data_dir = r'D:\\Research\\Python\\Data\\WIP\\Google search data Preprocessed'\n",
    "output_dir = r'D:\\Research\\Python\\Data\\WIP\\Final Association Rated'\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = [file for file in os.listdir(data_dir) if file.endswith('_preprocessed.csv')]\n",
    "\n",
    "# Initialize an empty list to store the top rows\n",
    "top_rows = []\n",
    "\n",
    "# Process each file\n",
    "for file in file_list:\n",
    "    if file != 'Search_Terms_Hashtags_preprocessed.csv':\n",
    "        # Extract date from the file name\n",
    "        date_str = file.split('_')[2]  # Assuming the date is at the third position\n",
    "        date = pd.to_datetime(date_str, format='%m-%d-%Y')  # Corrected format\n",
    "        \n",
    "        # Load the dataset and drop null rows from 'Combination' and 'Combined_text_preprocessed'\n",
    "        df = pd.read_csv(os.path.join(data_dir, file)).dropna(subset=['combination', 'Combined_text_preprocessed'])\n",
    "        \n",
    "        # Calculate cosine similarity for each row\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix_combined = vectorizer.fit_transform(df['combination'])\n",
    "        tfidf_matrix_text = vectorizer.transform(df['Combined_text_preprocessed'])\n",
    "        cosine_similarity_scores = cosine_similarity(tfidf_matrix_combined, tfidf_matrix_text)\n",
    "        \n",
    "        # Calculate SequenceMatcher similarity for each row\n",
    "        sequence_similarity_scores = []\n",
    "        for index, row in df.iterrows():\n",
    "            combination = row['combination']\n",
    "            combined_text = row['Combined_text_preprocessed']\n",
    "            sequence_similarity = SequenceMatcher(None, combination, combined_text).ratio()\n",
    "            sequence_similarity_scores.append(sequence_similarity)\n",
    "        \n",
    "        # Calculate Levenshtein distance for each row\n",
    "        levenshtein_distances = []\n",
    "        for index, row in df.iterrows():\n",
    "            combination = row['combination']\n",
    "            combined_text = row['Combined_text_preprocessed']\n",
    "            levenshtein_distance = fuzz.ratio(combination, combined_text)\n",
    "            max_length_of_strings = max(len(combination), len(combined_text))\n",
    "            normalized_levenshtein = levenshtein_distance / max_length_of_strings\n",
    "            levenshtein_distances.append(normalized_levenshtein)\n",
    "        \n",
    "        # Define weights for each metric (sum of weights should be 1)\n",
    "        weight_cosine = 0.4\n",
    "        weight_sequence = 0.3\n",
    "        weight_levenshtein = 0.3\n",
    "        \n",
    "        # Calculate overall scores for each row\n",
    "        overall_scores = []\n",
    "        for i in range(len(df)):\n",
    "            cosine_normalized = cosine_similarity_scores[i].mean()  # Average cosine similarity\n",
    "            sequence_normalized = sequence_similarity_scores[i]\n",
    "            levenshtein_normalized = 1 - levenshtein_distances[i]  # Inverted for correct interpretation\n",
    "            \n",
    "            overall_score = (\n",
    "                weight_cosine * cosine_normalized +\n",
    "                weight_sequence * sequence_normalized +\n",
    "                weight_levenshtein * levenshtein_normalized\n",
    "            )\n",
    "            overall_scores.append(overall_score)\n",
    "        \n",
    "        # Add the overall scores to the DataFrame\n",
    "        df['Cosine_Similarity'] = cosine_similarity_scores.mean(axis=1)\n",
    "        df['Sequence_Similarity'] = sequence_similarity_scores\n",
    "        df['Levenshtein_Distance'] = levenshtein_distances\n",
    "        df['Overall_Score'] = overall_scores\n",
    "        \n",
    "        # Select the top rows by Overall_Score and add to the list\n",
    "        top_rows.append(df.nlargest(10, 'Overall_Score'))  # Keep the top rows\n",
    "        \n",
    "        # Save the modified dataframe with a new name\n",
    "        new_filename = file.replace('_preprocessed.csv', f'_scores_{date_str}.csv')\n",
    "        df.to_csv(os.path.join(output_dir, new_filename), index=False)\n",
    "\n",
    "# Concatenate the top rows into a single dataframe\n",
    "final_df = pd.concat(top_rows, ignore_index=True)\n",
    "\n",
    "# Save the concatenated dataframe with top rows\n",
    "final_df.to_csv(os.path.join(output_dir, 'final_association_rated.csv'), index=False)\n",
    "\n",
    "print(\"Process completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
