{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "\n",
    "def train_lda_model(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    dtm = vectorizer.fit_transform(data['Text_Lemmatized'].tolist())\n",
    "    num_topics = 5\n",
    "    id2word = Dictionary([doc.split() for doc in data['Text_Lemmatized'].tolist()])\n",
    "    corpus = [id2word.doc2bow(doc.split()) for doc in data['Text_Lemmatized'].tolist()]\n",
    "    model = LdaModel(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
    "    return model\n",
    "\n",
    "def calculate_jaccard_similarity(topic_words1, topic_words2):\n",
    "    set1 = set(topic_words1)\n",
    "    set2 = set(topic_words2)\n",
    "    intersection_size = len(set1.intersection(set2))\n",
    "    union_size = len(set1.union(set2))\n",
    "    return intersection_size / union_size if union_size > 0 else 0.0\n",
    "\n",
    "def calculate_topic_diversity(lda_model):\n",
    "    # Get the top words for each topic from the LDA model\n",
    "    topics_words = [lda_model.get_topic_terms(topic, topn=10) for topic in range(lda_model.num_topics)]\n",
    "\n",
    "    # Calculate pairwise topic diversities using Jaccard similarity\n",
    "    topic_diversity_scores = []\n",
    "    for i in range(len(topics_words)):\n",
    "        for j in range(i + 1, len(topics_words)):\n",
    "            topic1_words = [lda_model.id2word[word_id] for word_id, _ in topics_words[i]]\n",
    "            topic2_words = [lda_model.id2word[word_id] for word_id, _ in topics_words[j]]\n",
    "            jaccard_similarity = calculate_jaccard_similarity(topic1_words, topic2_words)\n",
    "            topic_diversity_scores.append(jaccard_similarity)\n",
    "\n",
    "    # Calculate the average topic diversity score\n",
    "    if len(topic_diversity_scores) > 0:\n",
    "        average_topic_diversity = sum(topic_diversity_scores) / len(topic_diversity_scores)\n",
    "    else:\n",
    "        average_topic_diversity = 0.0\n",
    "\n",
    "    return average_topic_diversity\n",
    "\n",
    "\n",
    "def calculate_topic_coherence(lda_model, df):\n",
    "    vectorizer = CountVectorizer()\n",
    "    dtm = vectorizer.fit_transform(df['Text_Lemmatized'].tolist())\n",
    "    id2word = Dictionary([doc.split() for doc in df['Text_Lemmatized'].tolist()])\n",
    "    corpus = [id2word.doc2bow(doc.split()) for doc in df['Text_Lemmatized'].tolist()]\n",
    "\n",
    "    # Convert topics to list of strings\n",
    "    topics_words = [[lda_model.id2word[word_id] for word_id, _ in lda_model.get_topic_terms(topic, topn=10)] for topic in range(lda_model.num_topics)]\n",
    "\n",
    "    # Calculate CoherenceModel for c_v\n",
    "    coherence_model_c_v = CoherenceModel(topics=topics_words, texts=[doc.split() for doc in df['Text_Lemmatized'].tolist()], dictionary=id2word, coherence='c_v')\n",
    "    coherence_c_v = coherence_model_c_v.get_coherence()\n",
    "\n",
    "    # Calculate CoherenceModel for u_mass\n",
    "    coherence_model_u_mass = CoherenceModel(topics=topics_words, corpus=corpus, dictionary=id2word, coherence='u_mass')\n",
    "    coherence_u_mass = coherence_model_u_mass.get_coherence()\n",
    "\n",
    "    # Calculate CoherenceModel for c_uci\n",
    "    coherence_model_c_uci = CoherenceModel(topics=topics_words, texts=[doc.split() for doc in df['Text_Lemmatized'].tolist()], dictionary=id2word, coherence='c_uci')\n",
    "    coherence_c_uci = coherence_model_c_uci.get_coherence()\n",
    "\n",
    "    return coherence_model_c_v, coherence_model_u_mass, coherence_model_c_uci\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_topic_dominance(lda_model, df):\n",
    "    topic_dominance_scores = {topic_idx: 0.0 for topic_idx in range(lda_model.num_topics)}\n",
    "    total_documents = 0\n",
    "\n",
    "    # Get the topic-term matrix from the LDA model\n",
    "    topic_term_matrix = lda_model.get_topics()\n",
    "\n",
    "    # Normalize the topic-term matrix to get topic-term probabilities\n",
    "    topic_term_probabilities = topic_term_matrix / topic_term_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    # Create a bag-of-words representation for each document in the dataframe\n",
    "    id2word = Dictionary([doc.split() for doc in df['Text_Lemmatized'].tolist()])\n",
    "    corpus = [id2word.doc2bow(doc.split()) for doc in df['Text_Lemmatized'].tolist()]\n",
    "\n",
    "    # Iterate through each document and calculate the topic dominance\n",
    "    for doc_bow in corpus:\n",
    "        # Calculate the topic distribution for the document\n",
    "        topic_distribution = lda_model.get_document_topics(doc_bow, minimum_probability=0)\n",
    "\n",
    "        # Calculate the topic dominance score for each topic in the document\n",
    "        for topic_idx, prob in topic_distribution:\n",
    "            topic_dominance_scores[topic_idx] += prob\n",
    "        total_documents += 1\n",
    "\n",
    "    # Calculate the average topic dominance score for each topic\n",
    "    for topic_idx in topic_dominance_scores:\n",
    "        topic_dominance_scores[topic_idx] /= total_documents\n",
    "\n",
    "    return topic_dominance_scores\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    input_folder = r'D:\\Research\\Python\\Data\\WIP\\Spike Data'\n",
    "    output_folder = r'D:\\Research\\Python\\Data\\WIP\\Topic modelling'\n",
    "\n",
    "    # Get a list of all CSV files in the input folder\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Load data from CSV\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # LDA\n",
    "        lda_model = train_lda_model(df)\n",
    "\n",
    "        # Calculate perplexity score after training the model\n",
    "        vectorizer = CountVectorizer()\n",
    "        dtm = vectorizer.fit_transform(df['Text_Lemmatized'].tolist())\n",
    "        id2word = Dictionary([doc.split() for doc in df['Text_Lemmatized'].tolist()])\n",
    "        corpus = [id2word.doc2bow(doc.split()) for doc in df['Text_Lemmatized'].tolist()]\n",
    "        perplexity_score_lda = lda_model.log_perplexity(corpus)\n",
    "\n",
    "        coherence_model_c_v, coherence_model_u_mass, coherence_model_c_uci = calculate_topic_coherence(lda_model, df)\n",
    "\n",
    "        # Get coherence scores\n",
    "        coherence_c_v = coherence_model_c_v.get_coherence()\n",
    "        coherence_u_mass = coherence_model_u_mass.get_coherence()\n",
    "        coherence_c_uci = coherence_model_c_uci.get_coherence()\n",
    "\n",
    "        topic_diversity_score = calculate_topic_diversity(lda_model)\n",
    "        topic_dominance_scores = calculate_topic_dominance(lda_model, df)\n",
    "\n",
    "        # Create a dictionary to store the results\n",
    "        result_dict = {\n",
    "            'Dataset': filename,\n",
    "            'Perplexity_Score': perplexity_score_lda,\n",
    "            'Coherence_CV': coherence_c_v,\n",
    "            'Coherence_U_Mass': coherence_u_mass,\n",
    "            'Coherence_C_UCI': coherence_c_uci,\n",
    "            'Topic_Diversity': topic_diversity_score,\n",
    "            'Topic_Dominance_Scores': topic_dominance_scores,\n",
    "        }\n",
    "\n",
    "        all_results.append(result_dict)\n",
    "\n",
    "    # Save all results to a single CSV file\n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    result_file = os.path.join(output_folder, 'topic_model_metrics_LDA.csv')\n",
    "    result_df.to_csv(result_file, index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
