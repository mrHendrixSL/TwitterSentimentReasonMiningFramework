{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ3jE2X4D0hI"
   },
   "source": [
    "DO NOT RUN ALL! Contains Global Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: googletrans==3.1.0a0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (3.1.0a0)\n",
      "Requirement already satisfied: httpx==0.13.3 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from googletrans==3.1.0a0) (0.13.3)\n",
      "Requirement already satisfied: chardet==3.* in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2022.12.7)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
      "Requirement already satisfied: hstspreload in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.1.1)\n",
      "Requirement already satisfied: h2==3.* in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (22.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sup3r\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#Installing Libraries\n",
    "!pip install emoji\n",
    "!pip3 install googletrans==3.1.0a0\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from googletrans import Translator\n",
    "import nltk\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Z5soz29I0Eey"
   },
   "outputs": [],
   "source": [
    "#Define Clear Console function \n",
    "def clear_console():\n",
    "    os.system('cls' if os.name == 'nt' else 'clear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3doDH0H-dcz4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Query</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment          id                          Date     Query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "\n",
       "              User                                              Tweet  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file from local directory into a pandas DataFrame\n",
    "df_tweets = pd.read_csv('D:/Office laptop/colabDatasets-20230408T073310Z-001/colabDatasets/Training data/Training.data.csv', encoding='latin-1', header = None)\n",
    "df_tweets.columns=['Sentiment', 'id', 'Date', 'Query', 'User', 'Tweet']\n",
    "df_tweets.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1677429377193,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "6vZSjlwZn4OZ",
    "outputId": "694b04f8-5700-4972-9e28-f4e1be04383a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentiment  12000 non-null  int64 \n",
      " 1   id         12000 non-null  int64 \n",
      " 2   Date       12000 non-null  object\n",
      " 3   Query      12000 non-null  object\n",
      " 4   User       12000 non-null  object\n",
      " 5   Tweet      12000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 656.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677429377193,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "h6HdxEL8eNQp",
    "outputId": "4b734162-e427-4172-e6f9-7ea259fc26b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████████████████████████████████████████████████████████| 12000/12000 [00:00<00:00, 13270.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename the \"Text\" column to \"Original Text\"\n",
    "df_tweets = df_tweets.rename(columns={'Tweet': 'Original Text'})\n",
    "\n",
    "# Convert the \"Original Text\" column to a string data type\n",
    "df_tweets['Original Text'] = df_tweets['Original Text'].astype(str)\n",
    "\n",
    "# Create a duplicate column named \"Text\" with the values from the \"Original Text\" column\n",
    "with tqdm(total=len(df_tweets.index), desc=\"Processing\") as pbar:\n",
    "    for i, row in df_tweets.iterrows():\n",
    "        df_tweets.at[i, 'Text'] = row['Original Text']\n",
    "        pbar.update(1)\n",
    "\n",
    "print('Cell Complete')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NdtiaU0oqXAt"
   },
   "source": [
    "Extract_mentions_hashtags uses regular expressions to extract mentions (@\\w+) and hashtags (#\\w+) from the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5182,
     "status": "ok",
     "timestamp": 1677429382373,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "SCN8kdJ_q0YP",
    "outputId": "42a8adc8-e75a-452a-8ac5-427b1aa3767a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████████████████████████████████████████████████████████| 12000/12000 [00:01<00:00, 8813.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Sentiment      12000 non-null  int64 \n",
      " 1   id             12000 non-null  int64 \n",
      " 2   Date           12000 non-null  object\n",
      " 3   Query          12000 non-null  object\n",
      " 4   User           12000 non-null  object\n",
      " 5   Original Text  12000 non-null  object\n",
      " 6   Text           12000 non-null  object\n",
      " 7   Mentions       12000 non-null  object\n",
      " 8   Hashtags       12000 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 1.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def extract_mentions_hashtags(text):\n",
    "    mentions = re.findall(r'@\\w+', text)\n",
    "    hashtags = re.findall(r'#\\w+', text)\n",
    "    for mention in mentions:\n",
    "        text = text.replace(mention, '')\n",
    "    for hashtag in hashtags:\n",
    "        text = text.replace(hashtag, '')\n",
    "    return ','.join(mentions), ','.join(hashtags), text\n",
    "\n",
    "with tqdm(total=len(df_tweets.index), desc=\"Processing\") as pbar:\n",
    "    for i, row in df_tweets.iterrows():\n",
    "        df_tweets.at[i, 'Mentions'], df_tweets.at[i, 'Hashtags'], df_tweets.at[i, 'Text'] = extract_mentions_hashtags(row['Text'])\n",
    "        pbar.update(1)\n",
    "\n",
    "print('Cell Complete')\n",
    "df_tweets.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0s8p9RnmHeG"
   },
   "source": [
    "Define a function remove_urls that removes URLs from a given text using regular expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2528,
     "status": "ok",
     "timestamp": 1677429384897,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "ll-GK5WRmGto",
    "outputId": "d6a30cfa-22f3-43ef-c514-060d4aefe627"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                                    | 1/12000 [00:00<07:03, 28.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Sentiment         12000 non-null  int64 \n",
      " 1   id                12000 non-null  int64 \n",
      " 2   Date              12000 non-null  object\n",
      " 3   Query             12000 non-null  object\n",
      " 4   User              12000 non-null  object\n",
      " 5   Original Text     12000 non-null  object\n",
      " 6   Text              12000 non-null  object\n",
      " 7   Mentions          12000 non-null  object\n",
      " 8   Hashtags          12000 non-null  object\n",
      " 9   URL Removed Text  12000 non-null  object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub('', text)\n",
    "\n",
    "with tqdm(total=len(df_tweets.index), desc=\"Processing\") as pbar:\n",
    "    df_tweets['URL Removed Text'] = df_tweets['Text'].apply(lambda x: remove_urls(x))\n",
    "    pbar.update(1)\n",
    "\n",
    "print('Cell Complete')\n",
    "df_tweets.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BV-vIUOXhQF-"
   },
   "source": [
    "**Emoji Handling**\n",
    "replaces emojis and emoticons with relevant words using the emoji 2.2.0 library:\n",
    "\n",
    "The replace_emoji function uses the demojize method of the emoji library to convert emojis to their textual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49170,
     "status": "ok",
     "timestamp": 1677429434055,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "Kr0hF3xHfeDr",
    "outputId": "7af49640-2cbd-4607-ee0f-0956165a9fe7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                                    | 1/12000 [00:00<48:11,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji Library Installed\n",
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Sentiment           12000 non-null  int64 \n",
      " 1   id                  12000 non-null  int64 \n",
      " 2   Date                12000 non-null  object\n",
      " 3   Query               12000 non-null  object\n",
      " 4   User                12000 non-null  object\n",
      " 5   Original Text       12000 non-null  object\n",
      " 6   Text                12000 non-null  object\n",
      " 7   Mentions            12000 non-null  object\n",
      " 8   Hashtags            12000 non-null  object\n",
      " 9   URL Removed Text    12000 non-null  object\n",
      " 10  Emoji Removed Text  12000 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_emoji(text):\n",
    "    return emoji.demojize(text).replace(\":\",\" \")\n",
    "\n",
    "with tqdm(total=len(df_tweets.index), desc=\"Processing\") as pbar:\n",
    "    df_tweets['Emoji Removed Text'] = df_tweets['URL Removed Text'].apply(lambda x: replace_emoji(x))\n",
    "    pbar.update(1)\n",
    "    \n",
    "clear_console()\n",
    "print('emoji Library Installed')\n",
    "print('Cell Complete')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmOdL06wji4M"
   },
   "source": [
    "Replace all underscores with spaces in the \"text\" column of the \"df_tweets\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1007,
     "status": "ok",
     "timestamp": 1677429435056,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "Ugku0HC5hX_u",
    "outputId": "d65235ca-92f9-4bf2-8e90-4b42e882e900"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Sentiment                 12000 non-null  int64 \n",
      " 1   id                        12000 non-null  int64 \n",
      " 2   Date                      12000 non-null  object\n",
      " 3   Query                     12000 non-null  object\n",
      " 4   User                      12000 non-null  object\n",
      " 5   Original Text             12000 non-null  object\n",
      " 6   Text                      12000 non-null  object\n",
      " 7   Mentions                  12000 non-null  object\n",
      " 8   Hashtags                  12000 non-null  object\n",
      " 9   URL Removed Text          12000 non-null  object\n",
      " 10  Emoji Removed Text        12000 non-null  object\n",
      " 11  Character Processed Text  12000 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets['Character Processed Text'] = df_tweets['Emoji Removed Text'].str.replace('_', ' ')\n",
    "print('Cell Complete')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIK3mxFrk8Ed"
   },
   "source": [
    "replaces multiple spaces with a single space in the \"Text\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10215,
     "status": "ok",
     "timestamp": 1677429445644,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "VlqCL1aMj-XH",
    "outputId": "58811cc4-ecf9-44a8-c19c-5057b9bbcf3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sup3r\\AppData\\Local\\Temp\\ipykernel_15956\\2964014356.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_tweets['Character Processed Text'] = df_tweets['Character Processed Text'].str.replace(' +', ' ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Sentiment                 12000 non-null  int64 \n",
      " 1   id                        12000 non-null  int64 \n",
      " 2   Date                      12000 non-null  object\n",
      " 3   Query                     12000 non-null  object\n",
      " 4   User                      12000 non-null  object\n",
      " 5   Original Text             12000 non-null  object\n",
      " 6   Text                      12000 non-null  object\n",
      " 7   Mentions                  12000 non-null  object\n",
      " 8   Hashtags                  12000 non-null  object\n",
      " 9   URL Removed Text          12000 non-null  object\n",
      " 10  Emoji Removed Text        12000 non-null  object\n",
      " 11  Character Processed Text  12000 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets['Character Processed Text'] = df_tweets['Character Processed Text'].str.replace(' +', ' ')\n",
    "print('Cell Complete')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MySqOWiMm2xt"
   },
   "source": [
    "Remove non-alphanumeric characters from text in a DataFrame column using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4994,
     "status": "ok",
     "timestamp": 1677429450627,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "HRsF7g4elOCW",
    "outputId": "df86dc24-9185-4127-a0a3-c70733bddbeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Sentiment                 12000 non-null  int64 \n",
      " 1   id                        12000 non-null  int64 \n",
      " 2   Date                      12000 non-null  object\n",
      " 3   Query                     12000 non-null  object\n",
      " 4   User                      12000 non-null  object\n",
      " 5   Original Text             12000 non-null  object\n",
      " 6   Text                      12000 non-null  object\n",
      " 7   Mentions                  12000 non-null  object\n",
      " 8   Hashtags                  12000 non-null  object\n",
      " 9   URL Removed Text          12000 non-null  object\n",
      " 10  Emoji Removed Text        12000 non-null  object\n",
      " 11  Character Processed Text  12000 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "def remove_non_alphanumeric(text):\n",
    "    pattern = re.compile(r'[^a-zA-Z0-9 @\\#]+')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "df_tweets['Character Processed Text'] = df_tweets['Character Processed Text'].apply(remove_non_alphanumeric)\n",
    "print('Cell Complete')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLWY-qJZuCFJ"
   },
   "source": [
    "str.lower() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 988,
     "status": "ok",
     "timestamp": 1677429451604,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "teNRW-imtoV3",
    "outputId": "b0b06b4c-1c3a-43af-8965-c6c44305923b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 212188 to 1403939\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Sentiment                 12000 non-null  int64 \n",
      " 1   id                        12000 non-null  int64 \n",
      " 2   Date                      12000 non-null  object\n",
      " 3   Query                     12000 non-null  object\n",
      " 4   User                      12000 non-null  object\n",
      " 5   Original Text             12000 non-null  object\n",
      " 6   Text                      12000 non-null  object\n",
      " 7   Mentions                  12000 non-null  object\n",
      " 8   Hashtags                  12000 non-null  object\n",
      " 9   URL Removed Text          12000 non-null  object\n",
      " 10  Emoji Removed Text        12000 non-null  object\n",
      " 11  Character Processed Text  12000 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets['Character Processed Text'] = df_tweets['Character Processed Text'].str.lower()\n",
    "print('Cell Complete')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgO3EhP9yjIx"
   },
   "source": [
    "Remove any rows in df_tweets where the \"Text\" column has only whitespaces or is empty after the above preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1968,
     "status": "ok",
     "timestamp": 1677429453570,
     "user": {
      "displayName": "Rasika Chamara",
      "userId": "07483029762731546054"
     },
     "user_tz": -330
    },
    "id": "4Z6aJy5BzGBP",
    "outputId": "0c931d09-513b-4bc8-ebf1-444b19eb2f87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11969 entries, 212188 to 1403939\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Sentiment                 11969 non-null  int64 \n",
      " 1   id                        11969 non-null  int64 \n",
      " 2   Date                      11969 non-null  object\n",
      " 3   Query                     11969 non-null  object\n",
      " 4   User                      11969 non-null  object\n",
      " 5   Original Text             11969 non-null  object\n",
      " 6   Text                      11969 non-null  object\n",
      " 7   Mentions                  11969 non-null  object\n",
      " 8   Hashtags                  11969 non-null  object\n",
      " 9   URL Removed Text          11969 non-null  object\n",
      " 10  Emoji Removed Text        11969 non-null  object\n",
      " 11  Character Processed Text  11969 non-null  object\n",
      "dtypes: int64(2), object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets = df_tweets[df_tweets['Character Processed Text'].astype(str).str.strip() != '']\n",
    "print('Cell Complete')\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_DH3HxSN1BiL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Trans Imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11969/11969 [42:29<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Translate the other languages to english\n",
    "import googletrans\n",
    "from googletrans import *\n",
    "translator = googletrans.Translator()\n",
    "print('Google Trans Imported')\n",
    "\n",
    "df_tweets['Character Processed Text'] = df_tweets['Character Processed Text'].astype(str) # changing datatype to string\n",
    "\n",
    "# Add a progress bar to show the translation progress\n",
    "with tqdm(total=len(df_tweets)) as pbar:\n",
    "    def translate_text(row):\n",
    "        if detect(row['Character Processed Text']) != 'en':\n",
    "            translated_text = translator.translate(row['Character Processed Text'], src='auto', dest='en').text\n",
    "        else:\n",
    "            translated_text = row['Character Processed Text']\n",
    "        pbar.update(1)\n",
    "        return translated_text\n",
    "\n",
    "    df_tweets['Translated Text'] = df_tweets.apply(translate_text, axis=1)\n",
    "\n",
    "print('Cell Complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sup3r\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 11969/11969 [00:02<00:00, 4411.82it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download NLTK stop words\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load stop words\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Define a function to remove stop words from text\n",
    "def remove_stop_words(text):\n",
    "    # Tokenize text\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    # Join words\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply function to \"Translated Text\" column of DataFrame\n",
    "df_tweets['Translated Text'] = df_tweets['Translated Text'].apply(remove_stop_words)\n",
    "\n",
    "# Add progress bar using tqdm\n",
    "for i, row in tqdm(df_tweets.iterrows(), total=df_tweets.shape[0]):\n",
    "    df_tweets.at[i, 'Stopword Processed Text'] = remove_stop_words(row['Translated Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11969/11969 [01:05<00:00, 183.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define a function to tokenize using spaCy\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenize function to the 'Text' column with progress bar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df_tweets['Text_Tokenized'] = df_tweets['Stopword Processed Text'].progress_apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11969/11969 [01:05<00:00, 183.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define a function to perform lemmatizing using spaCy\n",
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    return lemmas\n",
    "\n",
    "# Apply the lemmatize function to the 'Text' column with progress bar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df_tweets['Text_Lemmatized'] = df_tweets['Stopword Processed Text'].progress_apply(lemmatize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11969 entries, 212188 to 1403939\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Sentiment                 11969 non-null  int64 \n",
      " 1   id                        11969 non-null  int64 \n",
      " 2   Date                      11969 non-null  object\n",
      " 3   Query                     11969 non-null  object\n",
      " 4   User                      11969 non-null  object\n",
      " 5   Original Text             11969 non-null  object\n",
      " 6   Text                      11969 non-null  object\n",
      " 7   Mentions                  11969 non-null  object\n",
      " 8   Hashtags                  11969 non-null  object\n",
      " 9   URL Removed Text          11969 non-null  object\n",
      " 10  Emoji Removed Text        11969 non-null  object\n",
      " 11  Character Processed Text  11969 non-null  object\n",
      " 12  Translated Text           11969 non-null  object\n",
      " 13  Stopword Processed Text   11969 non-null  object\n",
      " 14  Text_Tokenized            11969 non-null  object\n",
      " 15  Text_Lemmatized           11969 non-null  object\n",
      "dtypes: int64(2), object(14)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_tweets.to_csv(r'D:/Office laptop/colabDatasets-20230408T073310Z-001/colabDatasets/Training data/.data.Preprocessed.csv', encoding='latin-1')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNTXn0C813JjzDjtj++cTE5",
   "mount_file_id": "1p0p77x7wU2uvrI0FoXOR5oY1X1wTdkKz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
